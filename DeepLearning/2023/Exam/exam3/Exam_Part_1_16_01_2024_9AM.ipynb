{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hY88PZuGRlvk"
      },
      "source": [
        "# **Final Exam for Deep Network Development course. First part (mandatory)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "994g3vW4RpXr"
      },
      "source": [
        "This notebook contains the task to be solved in order to pass the exam.\n",
        "This is the first part of the exam, which is compolsury in order to get a grade. It contains a task similar to what you have worked on during the semester, which consists on implementing a network architecture and a function.\n",
        "\n",
        "Please note that, to **PASS** the Deep Network Development course you must **SUBMIT A SUCCESSFUL SOLUTION FOR THE FIRST PART**. If you **FAIL** the first part, you have the right to do the exam **ONE MORE TIME**. If you **FAIL AGAIN**, then unfortunately, you have failed the course. If you **PASS** the first part, then you get the weighted average of your quizzes and assignments as your final grade."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KhN7-a6UiJjL"
      },
      "source": [
        "## Your information\n",
        "Please fill the next cell with your information"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7b0b9HjOdk2F"
      },
      "source": [
        "**Full Name**:\n",
        "\n",
        "**Neptun code:**\n",
        "\n",
        "**Date:** 16/01/2024 9AM-10AM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krzdzOL0Sejg"
      },
      "source": [
        "## Task Description"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjArI5jdUlLv"
      },
      "source": [
        "#### Your task is to implement a custom architecture layers and the forward functions.\n",
        "\n",
        "#### Afterwards, make sure to run the last cell code to check if your implementation is correct.\n",
        "\n",
        "#### This task should be **SOLVED IN 1 HOUR** and submitted to Canvas (download the .ipynb file). Please note that after 1 hour, the Canvas exam assignment will be closed and you cannot submit your solution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8C4gtZ-Xqe6y"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "G9UZ9Gci_k3d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = torch.device(\"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwErjN2yP2O0"
      },
      "source": [
        "# Architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1WbOZj1PkVa"
      },
      "source": [
        "Please right click the image and \"Open image in a new tab\" to view it better with zoom. Or download it from here: https://drive.google.com/file/d/1I4GNCq7OnANpLfknHFox52wnzlBnvmTj/view?usp=sharing\n",
        "\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "![](https://drive.google.com/uc?id=1I4GNCq7OnANpLfknHFox52wnzlBnvmTj)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCCilL8Pqzo-"
      },
      "source": [
        "# Text Encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "LxyvYiODqhqw"
      },
      "outputs": [],
      "source": [
        "class TextEncoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(TextEncoder, self).__init__()\n",
        "        #IMPLEMENT LAYERS\n",
        "\n",
        "    def forward(self, text):\n",
        "        #IMPLEMENT FORWARD STEP\n",
        "\n",
        "\n",
        "        # reshape embedding output to fit feed forward layer\n",
        "\n",
        "        return"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RR2x8x4oAL9x"
      },
      "source": [
        "# Combined Text-Image Encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "y5hBX97M1p2f"
      },
      "outputs": [],
      "source": [
        "class CombinedTextImageEncoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CombinedTextImageEncoder, self).__init__()\n",
        "        # IMPLEMENT LAYERS\n",
        "\n",
        "\n",
        "    def forward(self, encoded_text):\n",
        "      # IMPLEMENT FORWARD STEP\n",
        "\n",
        "      # implement conv layers\n",
        "\n",
        "\n",
        "      #reshape output to fit Linear\n",
        "\n",
        "      #add batch number to Linears output\n",
        "\n",
        "      return"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYbJkD0gEWaF"
      },
      "source": [
        "#Combined Text-Image Decoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "PZd9RNzkESmI"
      },
      "outputs": [],
      "source": [
        "class CombinedTextImageDecoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CombinedTextImageDecoder, self).__init__()\n",
        "        #IMPLEMENT LAYERS\n",
        "\n",
        "\n",
        "    def forward(self, features):\n",
        "      # IMPLEMENT FORWARD PASS FOLLOW INSTRUCTIONS\n",
        "\n",
        "      #reshape GRU output to fit conv2D\n",
        "\n",
        "      #reshape Linear output to fit concatenation\n",
        "\n",
        "      return"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqKSnz3BrCO3"
      },
      "source": [
        "# Combining everything"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "jvcrkVnbql8B"
      },
      "outputs": [],
      "source": [
        "class TextToImageModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(TextToImageModel, self).__init__()\n",
        "        self.textencoder = TextEncoder()\n",
        "        self.encoder = CombinedTextImageEncoder()\n",
        "        self.decoder = CombinedTextImageDecoder()\n",
        "        #write the layer with the interrogation mark\n",
        "\n",
        "    def forward(self, text):\n",
        "      text_features = self.textencoder(text)\n",
        "      #making random noise image\n",
        "      image = torch.rand(256, 256, 3).numpy()\n",
        "      image = (image * 255).astype(np.uint8)\n",
        "      image = np.rollaxis(image, 2, 0)\n",
        "      input_image = torch.from_numpy(image) # Convert image to torch tensor\n",
        "      input_image = torch.unsqueeze(input_image, dim=0) # Add a batch dimension of 1\n",
        "\n",
        "      # do the block with the interogation mark\n",
        "\n",
        "      #reshape features to fit addition\n",
        "\n",
        "      #write other layers\n",
        "\n",
        "\n",
        "      return"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9GyFNHRrJG2"
      },
      "source": [
        "# Trying Out the whole architecture DO NOT MODIFY THESE CELLS!!!!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "tlu8rC8Rp1xq"
      },
      "outputs": [],
      "source": [
        "text = \"Brown fox jumps over the lazy dog\"\n",
        "\n",
        "# Simple preprocessing the text\n",
        "word_to_ix = {\"Brown\": 0, \"fox\": 1, \"jumps\": 2, \"over\": 3, \"the\": 4, \"lazy\": 5, \"dog\":6}\n",
        "input_tensor = torch.tensor(list(word_to_ix.values()), dtype=torch.long) # a tensor representing words by integers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "MzcCRA1oK1Ty"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'NoneType' object has no attribute 'shape'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[8], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      3\u001b[0m output \u001b[38;5;241m=\u001b[39m model(input_tensor)\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m output\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m (\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m256\u001b[39m,\u001b[38;5;241m256\u001b[39m)\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
          ]
        }
      ],
      "source": [
        "model = TextToImageModel()\n",
        "model = model.to(device)\n",
        "output = model(input_tensor)\n",
        "print(output.shape)\n",
        "assert output.shape == (1,3,256,256)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
