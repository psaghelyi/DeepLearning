{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Final Exam for Deep Network Development course. First part (mandatory)**"
      ],
      "metadata": {
        "id": "hY88PZuGRlvk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook contains the task to be solved in order to pass the exam.\n",
        "This is the first part of the exam, which is compolsury in order to get a grade. It contains a task similar to what you have worked on during the semester, which consists on implementing a network architecture and a function.\n",
        "\n",
        "Please note that, to **PASS** the Deep Network Development course you must **SUBMIT A SUCCESSFUL SOLUTION FOR THE FIRST PART**. If you **FAIL** the first part, you have the right to do the exam **ONE MORE TIME**. If you **FAIL AGAIN**, then unfortunately, you have failed the course. If you **PASS** the first part, then you get the weighted average of your quizzes and assignments as your final grade."
      ],
      "metadata": {
        "id": "994g3vW4RpXr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Your information\n",
        "Please fill the next cell with your information"
      ],
      "metadata": {
        "id": "KhN7-a6UiJjL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Full Name**:\n",
        "\n",
        "**Neptun code:**\n",
        "\n",
        "**Date:** 16/01/2024 9AM-10AM"
      ],
      "metadata": {
        "id": "7b0b9HjOdk2F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task Description"
      ],
      "metadata": {
        "id": "krzdzOL0Sejg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Your task is to implement a custom architecture layers and the forward functions.\n",
        "\n",
        "#### Afterwards, make sure to run the last cell code to check if your implementation is correct.\n",
        "\n",
        "#### This task should be **SOLVED IN 1 HOUR** and submitted to Canvas (download the .ipynb file). Please note that after 1 hour, the Canvas exam assignment will be closed and you cannot submit your solution."
      ],
      "metadata": {
        "id": "vjArI5jdUlLv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "8C4gtZ-Xqe6y"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cpu\")\n",
        "device"
      ],
      "metadata": {
        "id": "G9UZ9Gci_k3d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55149c7c-c11f-4add-9ec4-c944acdaeb9d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Architecture"
      ],
      "metadata": {
        "id": "KwErjN2yP2O0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Please right click the image and \"Open image in a new tab\" to view it better with zoom. Or download it from here: https://drive.google.com/file/d/1I4GNCq7OnANpLfknHFox52wnzlBnvmTj/view?usp=sharing\n",
        "\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "![](https://drive.google.com/uc?id=1I4GNCq7OnANpLfknHFox52wnzlBnvmTj)\n"
      ],
      "metadata": {
        "id": "J1WbOZj1PkVa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Encoder"
      ],
      "metadata": {
        "id": "eCCilL8Pqzo-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TextEncoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(TextEncoder, self).__init__()\n",
        "        #IMPLEMENT LAYERS\n",
        "        self.embedding = nn.Embedding(num_embeddings=7, embedding_dim=512)\n",
        "\n",
        "        self.linear = nn.Linear(in_features=3584, out_features=2048)\n",
        "        self.linear2 = nn.Linear(in_features=2048, out_features=12288)\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, text):\n",
        "        #IMPLEMENT FORWARD STEP\n",
        "        text = self.embedding(text)\n",
        "\n",
        "        text_flattened = text.view(1,3584)\n",
        "        print(\"text_flattened\", text_flattened.shape)\n",
        "\n",
        "        text = self.linear(text_flattened)\n",
        "        print(\"text-linaer\", text.shape)\n",
        "        text = self.relu(text)\n",
        "        text = self.linear2(text)\n",
        "        text = self.relu(text)\n",
        "\n",
        "        print(\"text\", text.shape)\n",
        "\n",
        "\n",
        "        # reshape embedding output to fit feed forward layer\n",
        "\n",
        "        text = text.view(1,3,64,64)\n",
        "        print(\"text-reshaped\", text.shape)\n",
        "\n",
        "        return text"
      ],
      "metadata": {
        "id": "LxyvYiODqhqw"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Combined Text-Image Encoder"
      ],
      "metadata": {
        "id": "RR2x8x4oAL9x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CombinedTextImageEncoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CombinedTextImageEncoder, self).__init__()\n",
        "        # IMPLEMENT LAYERS\n",
        "\n",
        "\n",
        "    def forward(self, encoded_text):\n",
        "      # IMPLEMENT FORWARD STEP\n",
        "\n",
        "      # implement conv layers\n",
        "\n",
        "\n",
        "      #reshape output to fit Linear\n",
        "\n",
        "      #add batch number to Linears output\n",
        "\n",
        "      return"
      ],
      "metadata": {
        "id": "y5hBX97M1p2f"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Combined Text-Image Decoder"
      ],
      "metadata": {
        "id": "EYbJkD0gEWaF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CombinedTextImageDecoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CombinedTextImageDecoder, self).__init__()\n",
        "        #IMPLEMENT LAYERS\n",
        "\n",
        "\n",
        "    def forward(self, features):\n",
        "      # IMPLEMENT FORWARD PASS FOLLOW INSTRUCTIONS\n",
        "\n",
        "      #reshape GRU output to fit conv2D\n",
        "\n",
        "      #reshape Linear output to fit concatenation\n",
        "\n",
        "      return"
      ],
      "metadata": {
        "id": "PZd9RNzkESmI"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Combining everything"
      ],
      "metadata": {
        "id": "zqKSnz3BrCO3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TextToImageModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(TextToImageModel, self).__init__()\n",
        "        self.textencoder = TextEncoder()\n",
        "        self.encoder = CombinedTextImageEncoder()\n",
        "        self.decoder = CombinedTextImageDecoder()\n",
        "        #write the layer with the interrogation mark\n",
        "\n",
        "    def forward(self, text):\n",
        "      text_features = self.textencoder(text)\n",
        "      #making random noise image\n",
        "      image = torch.rand(256, 256, 3).numpy()\n",
        "      image = (image * 255).astype(np.uint8)\n",
        "      image = np.rollaxis(image, 2, 0)\n",
        "      input_image = torch.from_numpy(image) # Convert image to torch tensor\n",
        "      input_image = torch.unsqueeze(input_image, dim=0) # Add a batch dimension of 1\n",
        "\n",
        "      # do the block with the interogation mark\n",
        "\n",
        "      #reshape features to fit addition\n",
        "\n",
        "      #write other layers\n",
        "\n",
        "\n",
        "      return"
      ],
      "metadata": {
        "id": "jvcrkVnbql8B"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Trying Out the whole architecture DO NOT MODIFY THESE CELLS!!!!\n"
      ],
      "metadata": {
        "id": "o9GyFNHRrJG2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Brown fox jumps over the lazy dog\"\n",
        "\n",
        "# Simple preprocessing the text\n",
        "word_to_ix = {\"Brown\": 0, \"fox\": 1, \"jumps\": 2, \"over\": 3, \"the\": 4, \"lazy\": 5, \"dog\":6}\n",
        "input_tensor = torch.tensor(list(word_to_ix.values()), dtype=torch.long) # a tensor representing words by integers"
      ],
      "metadata": {
        "id": "tlu8rC8Rp1xq"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = TextToImageModel()\n",
        "model = model.to(device)\n",
        "output = model(input_tensor)\n",
        "# print(output.shape)\n",
        "# assert output.shape == (1,3,256,256)"
      ],
      "metadata": {
        "id": "MzcCRA1oK1Ty",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e64e1f9-f299-4346-b373-d2a65dc49892"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text_flattened torch.Size([1, 3584])\n",
            "text-linaer torch.Size([1, 2048])\n",
            "text torch.Size([1, 12288])\n",
            "text-reshaped torch.Size([1, 3, 64, 64])\n"
          ]
        }
      ]
    }
  ]
}